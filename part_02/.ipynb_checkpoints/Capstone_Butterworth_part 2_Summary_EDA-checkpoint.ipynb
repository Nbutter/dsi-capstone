{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSI Capstone - Part 2 ### Nicholas Butterworth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis for DSI Capstone Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix, autocorrelation_plot\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('./assets/sampleSubmission')\n",
    "train = pd.read_csv('./assets/train')\n",
    "test = pd.read_csv('./assets/test')\n",
    "\n",
    "# note that we have ~10x more data in our training data set than in our testing data set\n",
    "print(f\"Sample submission shape: {sample.shape} - Train shape: {train.shape} - Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Examining the sample submission format\n",
    "\n",
    "sample.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the training data format\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the test data format - it looks identical to train except for the \"click\" column, as expected\n",
    "\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying that only \"click\" is present in train but not in test\n",
    "\n",
    "[item for item in list(train.columns.values) if item not in list(test.columns.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And that there are no columns in test which are not in train\n",
    "\n",
    "[item for item in list(test.columns.values) if item not in list(train.columns.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking nulls in training data - looks good\n",
    "\n",
    "train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And in test data - also looking good\n",
    "\n",
    "test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing data types \n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our class balance is 83% - 17% -- imbalanced classes although not as extreme as in other cases like disease detection\n",
    "# TODO: click through rates are typically well below 16% - worth reviewing the data notes to understand this better\n",
    "\n",
    "train.click.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a sense for the different columns in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique values does each column contain?\n",
    "\n",
    "unique_values = pd.DataFrame(index=train.columns)\n",
    "for col_name in list(train.columns):\n",
    "    unique_values.at[col_name, \"unique_vals\"] = len(train[col_name].unique())\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the numeric columns we have\n",
    "numeric_cols = train.select_dtypes(exclude='object').drop(columns=['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols.head()\n",
    "#sns.pairplot(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's examine the object columns in more detail since they will need to be transformed\n",
    "\n",
    "# these all look like anonymized categorical values... pretty straightforward\n",
    "train.select_dtypes(include='object').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looking into Hour... looks like it's a sequential list of dates with hour identifiers from 00 to 23 \n",
    "hour_counts = train.groupby(['hour']).size().reset_index(name='counts')\n",
    "hour_counts.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specifically this looks like observations drawn over a 10 day period\n",
    "# hour-of-the-day, day-of-the-week, and day-of-the-month may be relevant\n",
    "\n",
    "# \"Day One\" events by hour\n",
    "plt.xscale('linear')\n",
    "plt.plot(hour_counts.hour[0:24], hour_counts.counts[0:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Day Two\" events by hour\n",
    "plt.plot(hour_counts.hour[24:48], hour_counts.counts[24:48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial hypothesis : BalancedBaggingClassifier may perform well. Experiment: \"bin counting\" with probabilities to replace categoricals such as IP / device ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
