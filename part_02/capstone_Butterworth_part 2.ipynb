{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSI Capstone - Part 2 \n",
    "\n",
    "### Summary\n",
    "For my capstone project, I will be entering the Avazu Click-Through Rate Prediction competition on Kaggle (https://www.kaggle.com/c/avazu-ctr-prediction).  This competition ended three years ago but is still open for late submissions.\n",
    "\n",
    "### Goals\n",
    "My primary goal is to achieve a score which would have been sufficient to reach the top 1/3 of the leaderboard during the contest. This is a score of 0.3930207, which would have achieved a ranking of 534 of 1604 entrants (the precision is important for ranking in this contest, where many scores are separated by very small margins).  The top score in this contest was 0.3791384. Submissions are evaluated by Logarithmic Loss (lower scores are better). \n",
    "\n",
    "A secondary goal is to understand Neural Networks in depth since this is one of the model techniques I plan to use. \n",
    "\n",
    "A potential third (stretch) goal would be to test whether a model pipeline developed for this contest could be quickly repurposed for a different click prediction contest (eg https://www.kaggle.com/c/criteo-display-ad-challenge).  \n",
    "\n",
    "### Data\n",
    "This is a classification problem where the goal is to predict whether a user will click a given text ad. There are ~40MM rows in the training data set, representing 10 days of data from the Avazu site, and ~4MM rows in the test set, representing one day of data.  \n",
    "\n",
    "Preliminary data analysis follows in this notebook. In general the data appears to be well-formatted and consistent, with no null values present in either the test or the train set.\n",
    "\n",
    "\n",
    "### Methodology\n",
    "I plan to use a Neural Network approach to begin with, based on my interest in learning more about NN topology.  I am planning to use a Count Binarization technique to represent categorical values such as Device ID and Device IP with conditional probabilities. I am considering separate pipelines for ads which the model has seen before and ads which are new. All models will be cross-validated in training.\n",
    "\n",
    "The winning approaches for the Criteo competition (another click prediction competition) included such interesting techniques including Field Aware Factorization Machines and Vowpal Wabbit's implementation of Logistic Regression. One of these might be an interesting alternative to test once the Neural Network work reaches a good point.\n",
    "\n",
    "With 6GB of training data, I anticipate that model training and feature engieering may take time, depending on the approaches involved. I plan to create smaller test sets to use for initial model evaluation and fitting but do anticipate that final model training will be time-intensive. It is possible that I may look for a cloud instance with more cores/RAM than my local system, if necessary.  The local system is a dual-core Macbook Air with 8GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis for DSI Capstone Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix, autocorrelation_plot\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('./assets/sampleSubmission')\n",
    "train = pd.read_csv('./assets/train')\n",
    "test = pd.read_csv('./assets/test')\n",
    "\n",
    "# note that we have ~10x more data in our training data set than in our testing data set\n",
    "print(f\"Sample submission shape: {sample.shape} - Train shape: {train.shape} - Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Examining the sample submission format\n",
    "\n",
    "sample.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the training data format\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the test data format - it looks identical to train except for the \"click\" column, as expected\n",
    "\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying that only \"click\" is present in train but not in test\n",
    "\n",
    "[item for item in list(train.columns.values) if item not in list(test.columns.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And that there are no columns in test which are not in train\n",
    "\n",
    "[item for item in list(test.columns.values) if item not in list(train.columns.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking nulls in training data - looks good\n",
    "\n",
    "train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And in test data - also looking good\n",
    "\n",
    "test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing data types \n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our class balance is 83% - 17% -- imbalanced classes although not as extreme as in other cases like disease detection\n",
    "# TODO: click through rates are typically well below 16% - worth reviewing the data notes to understand this better\n",
    "\n",
    "train.click.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a sense for the different columns in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique values does each column contain?\n",
    "\n",
    "unique_values = pd.DataFrame(index=train.columns)\n",
    "for col_name in list(train.columns):\n",
    "    unique_values.at[col_name, \"unique_vals\"] = len(train[col_name].unique())\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the numeric columns we have\n",
    "numeric_cols = train.select_dtypes(exclude='object').drop(columns=['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols.head()\n",
    "#sns.pairplot(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's examine the object columns in more detail since they will need to be transformed\n",
    "\n",
    "# these all look like anonymized categorical values... pretty straightforward\n",
    "train.select_dtypes(include='object').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looking into Hour... looks like it's a sequential list of dates with hour identifiers from 00 to 23 \n",
    "hour_counts = train.groupby(['hour']).size().reset_index(name='counts')\n",
    "hour_counts.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specifically this looks like observations drawn over a 10 day period\n",
    "# hour-of-the-day, day-of-the-week, and day-of-the-month may be relevant\n",
    "\n",
    "# \"Day One\" events by hour\n",
    "plt.xscale('linear')\n",
    "plt.plot(hour_counts.hour[0:24], hour_counts.counts[0:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Day Two\" events by hour\n",
    "plt.plot(hour_counts.hour[24:48], hour_counts.counts[24:48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial hypothesis : BalancedBaggingClassifier may perform well. Experiment: \"bin counting\" with probabilities to replace categoricals such as IP / device ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
