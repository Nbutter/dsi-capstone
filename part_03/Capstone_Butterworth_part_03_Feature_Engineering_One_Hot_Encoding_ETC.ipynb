{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering With One Hot Encoding, CountVectorizer, HashingVectorizer\n",
    "\n",
    "In previous notebooks we experimented with FeatureHasher for encoding categorical variables with high dimensionality (~3MM feature columns). \n",
    "\n",
    "This notebook applies LabelEncoder and OneHotEncoder to categorical variables with smaller numbers of unique values (<10,000).  In addition we test CountVectorizer and HashingVectorizer.\n",
    "\n",
    "Since feature engineering for categorical variables (eg one hot encoding) is difficult with our full 6GB dataset on our local computer (8GB RAM), in this notebook we load ~25% of our training data (~10MM rows) to test our strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction import FeatureHasher \n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import classification_report, log_loss, roc_auc_score, roc_curve\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Test Data, Sample Submission and Partial Training Data\n",
    "\n",
    "Loading in our full test file as well as the sample submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.8 s, sys: 12.8 s, total: 59.6 s\n",
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_domain</th>\n",
       "      <th>...</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000009e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15706</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  click      hour    C1  banner_pos   site_id site_domain  \\\n",
       "0  1.000009e+18      0  14102100  1005           0  1fbe01fe    f3845767   \n",
       "\n",
       "  site_category    app_id app_domain ...  device_type device_conn_type    C14  \\\n",
       "0      28905ebd  ecad2386   7801e8d9 ...            1                2  15706   \n",
       "\n",
       "   C15  C16   C17  C18  C19  C20  C21  \n",
       "0  320   50  1722    0   35   -1   79  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in test data as well as the Sample Submission file\n",
    "sample = pd.read_csv('../assets/sampleSubmission')\n",
    "test = pd.read_csv('../assets/test')\n",
    "\n",
    "# Because of GitHub space limits (no files over 2GB), train data file was split into 5 pieces\n",
    "\n",
    "# Loading the first file with header row to use for column names -- about 20% of our full training dataset\n",
    "%time train = pd.read_csv(\"../assets/trainaa\")\n",
    "\n",
    "# Checking the columns present\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing Class Imbalance\n",
    "We have only 16% minority class representation in this reduced dataset. Let's see whether changing this balance results in better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.02 s, sys: 1.66 s, total: 5.68 s\n",
      "Wall time: 6.17 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: click, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting training dataset into minority and majority classes so we can downsample majority class\n",
    "train_0 = train[train.click == 0]\n",
    "train_1 = train[train.click == 1]\n",
    "\n",
    "# Reducing the majority class to be the same size as the minority class\n",
    "%time train_0_reduced = resample(train_0, replace=False, n_samples=train_1.shape[0], random_state=99)\n",
    "\n",
    "# Appending the reduced majority class to our minority class to make a new training set\n",
    "train = train_0_reduced.append(train_1)\n",
    "\n",
    "# Now we can see that each class accounts for about 50% of the rows in our dataset\n",
    "train.click.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Y Train\n",
    "We'll use the \"click\" column in the training set as our target or \"y\" series for training purposes, dropping it from our training dataframe.  We will also remove the \"id\" column, which does not add value for training purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a y_train with our click information\n",
    "y_train = train.click\n",
    "\n",
    "# From the Kaggle site, we know 'id' is just a record indicator, so we can drop it\n",
    "# along with the \"click\" column, which is our target\n",
    "train = train.drop(columns=['click', 'id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3322714, 22), (4577464, 23), (3322714,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking our shapes. We see that \"test\" has an extra column, because it still has \"id\". We'll drop this column next \n",
    "# after using it to prepare a submission dataframe, where we'll put our predictions\n",
    "(train.shape, test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: click, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking class balancce in y_train\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping a Submission Dataframe\n",
    "We take the \"id\" column and index from the \"test\" dataframe and add a \"click\" column, following the model of the sample submission file.  For now the click column is filled with zeros; later as we generate model predictions we will place them here, before saving this dataframe out as a csv to upload to Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3322714, 22), (4577464, 22), (4577464, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the submission dataframe and conforming types\n",
    "submit = pd.DataFrame(test.id, index=test.index)\n",
    "submit['click'] = 0.0\n",
    "submit['id'] = submit['id'].astype(np.uint64)\n",
    "\n",
    "# Dropping the id column from test\n",
    "test = test.drop(columns=\"id\")\n",
    "\n",
    "# Now we can verify that \"train\" and \"test\" have the same number of columns, as expected\n",
    "# We can also verify that the \"submit\" dataframe has the same number of rows as \"test\"\n",
    "(train.shape, test.shape, submit.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering: Date Columns\n",
    "We have a column representing hour/day/month/year for each hour in our 14 day sample (\"hour\"). We will convert this to a date-time object, then add feature columns based on the day of the week and the hour of the day.  Finally we will remove the hour column. We'll perform the same operation on both our \"train\" and \"test\" dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 'hour-of-the-day' column in train\n",
      "Created 'day-of-the-week' column in train\n",
      "Created 'hour-of-the-day' column in test\n",
      "Created 'day-of-the-week' column in test\n"
     ]
    }
   ],
   "source": [
    "# function to make day-of-week, hour-of-day features\n",
    "def make_date_features(dataframe, frame_name=\"dataframe\", date_col=\"hour\"): \n",
    "    date_obj = pd.to_datetime(dataframe[date_col])\n",
    "    \n",
    "    dataframe['hour-of-the-day'] = date_obj.dt.hour\n",
    "    print(f\"Created 'hour-of-the-day' column in {frame_name}\")\n",
    "    \n",
    "    dataframe['day-of-the-week'] = date_obj.dt.dayofweek\n",
    "    print(f\"Created 'day-of-the-week' column in {frame_name}\")\n",
    "\n",
    "# running \"train\" and \"test\" through our date features function to create the engineered columns \n",
    "make_date_features(train, \"train\", \"hour\")\n",
    "make_date_features(test, \"test\", \"hour\")\n",
    "\n",
    "# dropping the \"hour\" column now that we no longer need it\n",
    "train = train.drop(columns=[\"hour\"])\n",
    "test = test.drop(columns=[\"hour\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of categorical features\n",
    "\n",
    "We have multiple columns with large numbers of categorical values. In fact, from our documentation, we know that _all_ the columns are categorical, whether their datatype is \"object\" or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>device_ip</td>\n",
       "      <td>1128197</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>device_id</td>\n",
       "      <td>361531</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>device_model</td>\n",
       "      <td>6043</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_id</td>\n",
       "      <td>4252</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>site_domain</td>\n",
       "      <td>3464</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>site_id</td>\n",
       "      <td>2964</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C14</td>\n",
       "      <td>1002</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>app_domain</td>\n",
       "      <td>299</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C17</td>\n",
       "      <td>222</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C20</td>\n",
       "      <td>166</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C19</td>\n",
       "      <td>46</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C21</td>\n",
       "      <td>42</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>app_category</td>\n",
       "      <td>28</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>site_category</td>\n",
       "      <td>22</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C16</td>\n",
       "      <td>9</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C15</td>\n",
       "      <td>8</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>banner_pos</td>\n",
       "      <td>7</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C1</td>\n",
       "      <td>7</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>device_type</td>\n",
       "      <td>4</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C18</td>\n",
       "      <td>4</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>device_conn_type</td>\n",
       "      <td>4</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hour-of-the-day</td>\n",
       "      <td>1</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>day-of-the-week</td>\n",
       "      <td>1</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column Name Unique Values   Dtype\n",
       "0          device_ip       1128197  object\n",
       "1          device_id        361531  object\n",
       "2       device_model          6043  object\n",
       "3             app_id          4252  object\n",
       "4        site_domain          3464  object\n",
       "5            site_id          2964  object\n",
       "6                C14          1002   int64\n",
       "7         app_domain           299  object\n",
       "8                C17           222   int64\n",
       "9                C20           166   int64\n",
       "10               C19            46   int64\n",
       "11               C21            42   int64\n",
       "12      app_category            28  object\n",
       "13     site_category            22  object\n",
       "14               C16             9   int64\n",
       "15               C15             8   int64\n",
       "16        banner_pos             7   int64\n",
       "17                C1             7   int64\n",
       "18       device_type             4   int64\n",
       "19               C18             4   int64\n",
       "20  device_conn_type             4   int64\n",
       "21   hour-of-the-day             1   int64\n",
       "22   day-of-the-week             1   int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the number of unique values in each column of the training dataset\n",
    "uniques = pd.DataFrame(data=[train.columns.values, [len(train[col].unique()) for col in train.columns], [train[col].dtype for col in train.columns]]).T\n",
    "uniques = uniques.rename({0:'Column Name', 1:'Unique Values', 2:'Dtype'}, axis=1)\n",
    "uniques = uniques.sort_values(by='Unique Values', ascending=False).reset_index(drop=True)\n",
    "uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use OneHotEncoder (and LabelEncoder, if needed) on each feature from C14 on down.  Let's start with one feature (C14), following which we'll create a function to generate the appropriate pipelines for all these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoding an integer column \n",
    "Let's start with C14. Since this is a column containing integer values, we don't need to use a LabelEncoder and we can proceed directly to OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an encoder that we can dedicate to this column\n",
    "ohe_C14 = OneHotEncoder(handle_unknown='ignore') # so that we'll ignore any new values found in the test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Generating an encoded matrix from our C14 column as well as fitting this encoder on its values\n",
    "encoded_C14 = ohe_C14.fit_transform(train.C14.as_matrix().reshape(-1, 1)) # reshaping to 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Encoding the same column from our test database\n",
    "encoded_C14_test = ohe_C14.transform(test.C14.as_matrix().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3322714, 1002), (4577464, 1002))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoded_C14.shape, encoded_C14_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoding an Object Column with LabelEncoder\n",
    "Now let's apply OneHotEncoder to \"App Domain\". Since this column contains string values, we'll need to use LabelEncoder to convert them to integers first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use separate encoders for train and test -- OneHotEncoder will deal with any new values in test\n",
    "\n",
    "# Label-encoding the column in train \n",
    "label_encoded_app_domain = LabelEncoder().fit_transform(train.app_domain)\n",
    "\n",
    "# Using a different label encoder for the column in test\n",
    "label_encoded_app_domain_test = LabelEncoder().fit_transform(test.app_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3322714,), (4577464,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the resulting shapes. \n",
    "label_encoded_app_domain.shape, label_encoded_app_domain_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has different shape than during fitting. Expected 3322714, got 4577464.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9781dceb518e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Attempting to transform the test column... but running into an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mencoded_app_domain_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mohe_app_domain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_encoded_app_domain_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Open below to see error!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \"\"\"\n\u001b[1;32m   2074\u001b[0m         return _transform_selected(X, self._transform,\n\u001b[0;32m-> 2075\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2030\u001b[0m             raise ValueError(\"X has different shape than during fitting.\"\n\u001b[1;32m   2031\u001b[0m                              \u001b[0;34m\" Expected %d, got %d.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2032\u001b[0;31m                              % (indices.shape[0] - 1, n_features))\n\u001b[0m\u001b[1;32m   2033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2034\u001b[0m         \u001b[0;31m# We use only those categorical features of X that are known using fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has different shape than during fitting. Expected 3322714, got 4577464."
     ]
    }
   ],
   "source": [
    "# Instantiating a OneHotEncoder and fitting it on the encoded column from train\n",
    "# Since we set \"handle_unknown\" to \"ignore\", we expect the model to handle the extra \n",
    "ohe_app_domain = OneHotEncoder(handle_unknown=\"ignore\").fit(label_encoded_app_domain.reshape(1, -1)) \n",
    "\n",
    "# Transforming the train column with the fitted encoder\n",
    "encoded_app_domain = ohe_app_domain.transform(label_encoded_app_domain.reshape(1, -1))\n",
    "\n",
    "# Attempting to transform the test column... but running into an error\n",
    "encoded_app_domain_test = ohe_app_domain.transform(label_encoded_app_domain_test.reshape(1, -1))\n",
    "\n",
    "# Open below to see error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that \"handle_unknown = 'ignore'\" is not working as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizing An Object Column\n",
    "Since OneHotEncoder and LabelEncoder don't really address the issue of different values in train and test, let's try CountVectorizer instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "cvec = cvec.fit(train.app_domain)\n",
    "app_domain_cvec = cvec.transform(train.app_domain)\n",
    "app_domain_cvec_test = cvec.transform(test.app_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_domain_cvec.shape, app_domain_cvec_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! This worked very well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HashVectorizing An Object Column\n",
    "Now let's try HashVectorizer - this may end up being useful for our largest text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvec = HashingVectorizer()\n",
    "hvec = hvec.fit(train.app_domain)\n",
    "app_domain_hvec = hvec.transform(train.app_domain)\n",
    "app_domain_hvec_test = hvec.transform(test.app_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_domain_hvec.shape, app_domain_hvec_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like something we can use for object columns with over 1MM values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Feature Engineering Steps Planned\n",
    "After this review we now have a good feeling for which types of encoding to use as we build a pipeline.  \n",
    "\n",
    "For large object columns (1MM+ values) we will use HashingVectorizer.  \n",
    "\n",
    "For smaller object columns we will use CountVectorizer.\n",
    "\n",
    "For integer columns we will use OneHotEncoding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Multiple Columns With OneHotEncoding\n",
    "In theory we should be able to pass multiple columns to OneHotEncoder. Let's see how well that works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['C1', 'banner_pos', 'device_type', 'device_conn_type', 'C14', 'C15',\n",
       "        'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'hour-of-the-day',\n",
       "        'day-of-the-week'],\n",
       "       dtype='object'),\n",
       " Index(['C1', 'banner_pos', 'device_type', 'device_conn_type', 'C14', 'C15',\n",
       "        'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'hour-of-the-day',\n",
       "        'day-of-the-week'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking all our columns with datatypes and number of unique values\n",
    "train_numeric = train.select_dtypes(include='number')\n",
    "test_numeric = test.select_dtypes(include='number')\n",
    "train_numeric.columns, test_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X needs to contain only non-negative integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5793e274fa69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \"\"\"\n\u001b[0;32m-> 1956\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \"\"\"\n\u001b[1;32m   2018\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[0;32m-> 2019\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X needs to contain only non-negative integers.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1964\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m         if (isinstance(self.n_values, six.string_types) and\n",
      "\u001b[0;31mValueError\u001b[0m: X needs to contain only non-negative integers."
     ]
    }
   ],
   "source": [
    "# This test fails because we have negative values. We need to transform these to run OneHotEncoder.\n",
    "#ohe = OneHotEncoder()\n",
    "#ohe = ohe.fit(train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1         1743866\n",
       " 100084     218999\n",
       " 100148     135398\n",
       " 100111     122583\n",
       " 100077     113742\n",
       "Name: C20, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: C15 and C16 are banner ad dimensions and should be combined to a \"size\" variable\n",
    "# EDA shows that variable C20 has -1 as its most frequent value.\n",
    "\n",
    "train.C20.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    -1, 100075, 100181, 100151, 100156, 100176, 100191, 100084,\n",
       "       100081, 100020, 100143, 100177, 100076, 100000, 100079, 100111,\n",
       "       100192, 100119, 100162, 100148, 100139, 100194, 100031, 100172,\n",
       "       100083, 100070, 100062, 100131, 100021, 100202, 100160, 100077,\n",
       "       100199, 100189, 100088, 100033, 100046, 100228, 100074, 100002,\n",
       "       100060, 100064, 100200, 100144, 100039, 100114, 100087, 100101,\n",
       "       100096, 100217, 100241, 100173, 100150, 100094, 100097, 100003,\n",
       "       100193, 100103, 100182, 100185, 100105, 100166, 100019, 100005,\n",
       "       100004, 100149, 100034, 100050, 100109, 100049, 100012, 100233,\n",
       "       100155, 100210, 100128, 100052, 100013, 100057, 100048, 100152,\n",
       "       100161, 100130, 100183, 100086, 100065, 100195, 100188, 100022,\n",
       "       100170, 100221, 100126, 100215, 100190, 100225, 100113, 100053,\n",
       "       100055, 100061, 100037, 100028, 100141, 100072, 100212, 100059,\n",
       "       100106, 100016, 100001, 100117, 100025, 100168, 100063, 100112,\n",
       "       100205, 100248, 100153, 100040, 100058, 100133, 100171, 100124,\n",
       "       100224, 100107, 100068, 100051, 100229, 100032, 100073, 100135,\n",
       "       100165, 100029, 100024, 100244, 100137, 100090, 100121, 100010,\n",
       "       100179, 100071, 100026, 100041, 100095, 100206, 100123, 100054,\n",
       "       100056, 100082, 100091, 100093, 100122, 100043, 100163, 100099,\n",
       "       100186, 100213, 100108, 100178, 100175, 100138, 100246, 100132,\n",
       "       100098, 100078, 100169, 100027, 100157, 100100])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that all the other values are over 10000, so this will be easy to transform\n",
    "train.C20.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/pandas/core/generic.py:5886: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# Series.replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
    "train_numeric.C20.replace(to_replace=-1, value=1, inplace=True)\n",
    "test_numeric.C20.replace(to_replace=-1, value=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3322714, 1523), (4577464, 1523))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can run again without that error\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe = ohe.fit(train_numeric)\n",
    "numeric_encoded_train = ohe.transform(train_numeric)\n",
    "numeric_encoded_test = ohe.transform(test_numeric)\n",
    "numeric_encoded_train.shape, numeric_encoded_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! This can be one pipeline in a FeatureUnion against the whole dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful post on a technique to use DefaultDict for something similar.\n",
    "# https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CountVectorizer on a numeric column\n",
    "What about using CountVectorizer on numeric columns?\n",
    "\n",
    "To do this we need to convert all the integer values to strings. Potentially feasible with our full data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3322714, 7), (4577464, 7))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec2 = CountVectorizer()\n",
    "string_col_train = train['C1'].map(lambda x: str(x))\n",
    "string_col_test = test['C1'].map(lambda x: str(x))\n",
    "\n",
    "train_cvec2 = cvec2.fit_transform(string_col_train)\n",
    "test_cvec2 = cvec2.transform(string_col_test)\n",
    "\n",
    "train_cvec2.shape, test_cvec2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Stopper\n",
    "assert \"red\" == 'blue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing Predictions on OneHotEncoder Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632135657778551\n",
      "[0 1] [1727131 1595583]\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb = bnb.fit(numeric_encoded_train, y_train)\n",
    "y_hat_bnb = bnb.predict(numeric_encoded_train)\n",
    "print(roc_auc_score(y_train, y_hat_bnb))\n",
    "unique, counts = np.unique(y_hat_bnb, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "%time lr = lr.fit(numeric_encoded_train, y_train)\n",
    "y_hat_lr = lr.predict(numeric_encoded_train)\n",
    "print(roc_auc_score(y_train, y_hat_lr)) \n",
    "unique, counts = np.unique(y_hat_lr, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better results on these columns than we got on the feature hashed columns previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = xgboost()\n",
    "%time xg = xg.fit(numeric_encoded_train, y_train)\n",
    "y_hat_xg = xg.predict(numeric_encoded_train)\n",
    "print(roc_auc_score(y_train, y_hat_xg)) \n",
    "unique, counts = np.unique(y_hat_xg, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "%time rf = rf.fit(numeric_encoded_train, y_train)\n",
    "y_hat_rf = rf.predict(numeric_encoded_train)\n",
    "print(roc_auc_score(y_train, y_hat_rf)) \n",
    "unique, counts = np.unique(y_hat_rf, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "With undersampling of the majority class, we are able to see some positive impact on predictions from the FeatureHasher columns - however it is fairly minimal (+.05 Roc-Auc score). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
