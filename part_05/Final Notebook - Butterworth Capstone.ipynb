{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Capstone\n",
    "\n",
    "In this notebook we load ~10MM rows of data from the Kaggle Avazu click prediction competition.  We reduce this to 2MM rows for speed. We then create train/test splits, perform feature engineering, and then make predictions which we validate with our test split of data. Similar to the Kaggle competition we use Log Loss as our metric for evaluation of the model's performance.\n",
    "\n",
    "With the exception of a date column ('hour'), all of the columns in this data set are categorical, even though some are encoded as integers (source: Kaggle docs and boards).  After 'id' and 'hour' are dropped, therefore, all values are converted to strings, so that every column can be treated with a separate CountVectorizer which is fit on training data and which performs transformations on both training and test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction import FeatureHasher \n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import classification_report, log_loss, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.9 s, sys: 6.06 s, total: 47 s\n",
      "Wall time: 48.3 s\n"
     ]
    }
   ],
   "source": [
    "# Loading 10MM rows\n",
    "%time train = pd.read_csv(\"../assets/trainaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train before sampling: (9999999, 24)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of train before sampling: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking 2MM random rows\n",
    "train = train.sample(frac=0.2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train after sampling: (2000000, 24)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of train after sampling: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping un-needed columns\n",
    "train = train.drop(columns=['hour', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train.drop(columns=['click']), train['click'], random_state=99, stratify=train['click'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C1', 'banner_pos', 'site_id', 'site_domain', 'site_category', 'app_id',\n",
       "       'app_domain', 'app_category', 'device_id', 'device_ip', 'device_model',\n",
       "       'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18',\n",
       "       'C19', 'C20', 'C21'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From EDA we know there's a negative value here \n",
    "X_train.C20.replace(to_replace=-1, value=1, inplace=True)\n",
    "X_test.C20.replace(to_replace=-1, value=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two banner dimensions combined into one feature\n",
    "X_train['banner'] = X_train['C15'].map(str) + X_train['C16'].map(str)\n",
    "X_test['banner'] = X_test['C15'].map(str) + X_test['C16'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['C15', 'C16'])\n",
    "X_test = X_test.drop(columns=['C15', 'C16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values to strings since these are all categorical columns\n",
    "X_train = X_train.applymap(str)\n",
    "X_test = X_test.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = []\n",
    "test_vec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vectorized representation of all columns, while ensuring congruent shapes between train and test\n",
    "\n",
    "for col in columns:\n",
    "    cvec = CountVectorizer(stop_words=None, min_df=1, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "    train_transform = cvec.fit_transform(X_train[col])\n",
    "    test_transform = cvec.transform(X_test[col])\n",
    "    train_vec.append(train_transform)\n",
    "    test_vec.append(test_transform)\n",
    "    print(f\"completed {col}. train shape {train_transform.shape} - test shape {test_transform.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = sparse.hstack(train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = sparse.hstack(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train shape: {train_matrix.shape} Test shape: {test_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(train_matrix, y_train)\n",
    "y_pred_nb = nb.predict(test_matrix)\n",
    "results['NB'] = y_pred_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_loss(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')\n",
    "lr.fit(train_matrix, y_train)\n",
    "y_pred_lr = lr.predict(test_matrix)\n",
    "results['LR'] = y_pred_lr\n",
    "log_loss(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(train_matrix, y_train)\n",
    "y_pred_mlp = mlp.predict(test_matrix)\n",
    "results['MLP'] = y_pred_mlp\n",
    "log_loss(y_test, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['AVG'] = (results['NB'] + results['MLP'] + results['LR'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_test, results['AVG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, results['AVG']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "rf.fit(train_matrix, y_train)\n",
    "y_pred_rf = rf.predict(test_matrix)\n",
    "results['RF'] = y_pred_rf\n",
    "log_loss(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['AVG'] = (results['NB'] + results['MLP'] + results['LR'] + results['RF'])/4\n",
    "log_loss(y_test, results['AVG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, results['AVG']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
